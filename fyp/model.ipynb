{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import re\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import joblib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Reviews.csv')\n",
    "#df = df.sample(frac=0.5, random_state=42) #reduce samples (memory issues)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get sentiment using SentimentIntensityAnalyzer for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment annotation function\n",
    "def get_sentiment(text):\n",
    "    '''\n",
    "    Sentiment annotation function\n",
    "    arguments : text = text to be processed\n",
    "    '''\n",
    "    \n",
    "    #calculate sentiment based on intensity\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    sentiment_scores = sid.polarity_scores(text)\n",
    "\n",
    "    #assign label used for each classification\n",
    "    if sentiment_scores['compound'] >= 0.1:\n",
    "        return 'positive'\n",
    "    elif sentiment_scores['compound'] <= -0.1:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "df['sentiment'] = df['content'].apply(lambda x: get_sentiment(str(x)) if isinstance(x, float) else get_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  content sentiment\n",
      "56640   I really like the game but I also think that i...  positive\n",
      "111054  The reason I rate this game one star is becaus...  negative\n",
      "3015    Do not get this game something is in the cats ...   neutral\n",
      "54987   The game is good in some what ways... But when...  negative\n",
      "46804                                                Good  positive\n"
     ]
    }
   ],
   "source": [
    "# Print the selected columns in table format\n",
    "selected_columns = ['content', 'sentiment']\n",
    "sample_df = df[selected_columns].sample(n=5)\n",
    "\n",
    "print(sample_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply preprocessing to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#uses stopwords library from NLTK\n",
    "stop = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "#pre-processing function\n",
    "def pre_processing(text):\n",
    "    '''\n",
    "    Pre-processing text function\n",
    "    arguments : text = text to be pre-processed\n",
    "    '''\n",
    "    \n",
    "    #lowercasing & remove any symbols\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'\\W',' ', text)\n",
    "    \n",
    "    #handle negation\n",
    "    text = re.sub(r'\\bnot\\b', 'not_', text)\n",
    "    text = re.sub(r'\\bno\\b', 'no_', text)\n",
    "    \n",
    "    #split words in the text & remove stopwords\n",
    "    words = text.split()\n",
    "    text = ' '.join([word for word in words if word not in stop])\n",
    "    \n",
    "    return text\n",
    "\n",
    "#apply the pre-processing to the dataset\n",
    "df['content'] = df['content'].apply(pre_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  This app is good!!.\n",
      "After:  app good\n",
      "Before:  Nice. Not bad.\n",
      "After:  nice not_ bad\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"This app is good!!.\"\n",
    "print(\"Before: \", sample_text)\n",
    "print(\"After: \", pre_processing(sample_text))\n",
    "\n",
    "sample_text = \"Nice. Not bad.\"\n",
    "print(\"Before: \", sample_text)\n",
    "print(\"After: \", pre_processing(sample_text))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into features and labels and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into training and testing\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(\n",
    "    df['content'], \n",
    "    df['sentiment'], \n",
    "    test_size=0.1, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform text into numerical data using TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "#transform both training and testing into numerical data\n",
    "features_train = vectorizer.fit_transform(features_train)\n",
    "features_test = vectorizer.transform(features_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth of the decision tree: 2945\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "tree_depth = clf.tree_.max_depth\n",
    "print(\"Depth of the decision tree:\", tree_depth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export model & TF-IDF parameter using Joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.joblib']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, 'decision_tree_model.joblib')\n",
    "joblib.dump(vectorizer, 'vectorizer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load('decision_tree_model.joblib')\n",
    "vectorizer =joblib.load('vectorizer.joblib')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(features_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8463489287275907\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(labels_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.62      0.62      1727\n",
      "     neutral       0.76      0.76      0.76      1598\n",
      "    positive       0.91      0.91      0.91      8110\n",
      "\n",
      "    accuracy                           0.85     11435\n",
      "   macro avg       0.76      0.76      0.76     11435\n",
      "weighted avg       0.85      0.85      0.85     11435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(labels_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual input test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Text:  not_ good\n",
      "Vectorized Text:    (0, 22956)\t0.735979734276324\n",
      "  (0, 14896)\t0.6770035677413757\n",
      "Sentiment: ['negative']\n"
     ]
    }
   ],
   "source": [
    "review_input = input(\"Enter a review: \")\n",
    "review_preprocessed = pre_processing(review_input)\n",
    "print(\"Processed Text: \", review_preprocessed)\n",
    "review_preprocessed = vectorizer.transform([review_preprocessed])\n",
    "print(\"Vectorized Text: \", review_preprocessed)\n",
    "sentiment = clf.predict(review_preprocessed)\n",
    "print(\"Sentiment:\", sentiment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
