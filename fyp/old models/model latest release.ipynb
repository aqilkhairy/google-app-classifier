{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSP650: PROJECT <br>\n",
    "# TITLE: GOOGLE PLAY APPLICATION CLASSIFICATION BASED ON SENTIMENT ANALYSIS OF REVIEWS <br>\n",
    "SUPERVISOR: MADAM UMMU FATIHAH BINTI MOHD BAHRIN <br>\n",
    "SUPERVISEE: AQIL KHAIRY BIN HAMSANI (2021856342) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import nltk\n",
    "import joblib\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Reviews.csv\")\n",
    "data = data.sample(frac=0.1, random_state=42) #reduce samples (memory issues)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update nltk library (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords') #uncomment this to update stopwords package\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(nltk.corpus.stopwords.words('english'))\n",
    "data['original_content'] = data['content']\n",
    "data['content'] = data['content'].fillna('')\n",
    "data['content'] = data['content'].str.lower()\n",
    "data['content'] = data['content'].str.replace('[^\\w\\s]','', regex=True)\n",
    "data['content'] = data['content'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using TextBlob to classify the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    sentiment = blob.sentiment.polarity\n",
    "    if sentiment >= 0.1:\n",
    "        return 'positive'\n",
    "    elif sentiment <= -0.1:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "    \n",
    "data['sentiment'] = data['content'].apply(lambda x: get_sentiment(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show some of the content and it's sentiment after using TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: awesome cool fun funny ridiculous funny\n",
      "Sentiment: positive\n",
      "\n",
      "Content: I Like the music ðŸŽ¶ but give pop ok ðŸ‘Œ\n",
      "Sentiment: positive\n",
      "\n",
      "Content: Buggy and there is ads\n",
      "Sentiment: neutral\n",
      "\n",
      "Content: Why did you put silver in Sonic Force's but not blaze if you could please tell me why if not okay whatever but it would be amazing if you could play as silver and I'm not saying Sonic or shadow are bad cheaters but I would love to play silver and blaze and one more thing is I think Sonic needs more charters well if you could please let me know why thank you egg Man well be back by Winter so be careful bye\n",
      "Sentiment: positive\n",
      "\n",
      "Content: Love it!\n",
      "Sentiment: positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_data = data.sample(n=5)\n",
    "for i, row in sample_data.iterrows():\n",
    "    print(f\"Content: {row['original_content']}\\nSentiment: {row['sentiment']}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split datasets for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['content'], data['sentiment'], test_size=0.1, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize text into numerical format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text):\n",
    "    return [int(word in set(text.split())) for word in features]\n",
    "\n",
    "features = list(set(' '.join(X_train).split()))\n",
    "X_train_vect = np.array([vectorize_text(x) for x in X_train])\n",
    "X_test_vect = np.array([vectorize_text(x) for x in X_test])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save features as a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['features.joblib']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(features, 'features.joblib')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model using Joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['decision_tree_model.joblib']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the variable to file\n",
    "joblib.dump(clf, 'decision_tree_model.joblib')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load back model into new variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = joblib.load('decision_tree_model.joblib')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.58      0.51      0.54       120\n",
      "     neutral       0.76      0.81      0.78       180\n",
      "    positive       0.93      0.93      0.93       844\n",
      "\n",
      "    accuracy                           0.87      1144\n",
      "   macro avg       0.75      0.75      0.75      1144\n",
      "weighted avg       0.86      0.87      0.86      1144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = dt_model.predict(X_test_vect)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select 5 random testing to display the result of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "Review: good app easily\n",
      "Actual Sentiment: positive\n",
      "Predicted Sentiment: positive\n",
      "\n",
      "Sample 2:\n",
      "Review: quality songs low lot disturbance song please fix issue full version app song quality good lite version need fixed\n",
      "Actual Sentiment: positive\n",
      "Predicted Sentiment: positive\n",
      "\n",
      "Sample 3:\n",
      "Review: good game nc keep legendary mythic monster\n",
      "Actual Sentiment: positive\n",
      "Predicted Sentiment: positive\n",
      "\n",
      "Sample 4:\n",
      "Review: fantastic fair liked\n",
      "Actual Sentiment: positive\n",
      "Predicted Sentiment: positive\n",
      "\n",
      "Sample 5:\n",
      "Review: awesome app saved time cost moving around meetings\n",
      "Actual Sentiment: positive\n",
      "Predicted Sentiment: positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_indices = np.random.choice(len(X_test), size=5, replace=False)\n",
    "\n",
    "random_X_test = X_test.iloc[random_indices]\n",
    "random_y_test = y_test.iloc[random_indices]\n",
    "\n",
    "# Predict sentiment for the selected samples\n",
    "random_X_test_vect = np.array([vectorize_text(x) for x in random_X_test])\n",
    "random_y_pred = dt_model.predict(random_X_test_vect)\n",
    "\n",
    "# Print the random samples and their predicted sentiment\n",
    "for i in range(5):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"Review: {random_X_test.iloc[i]}\")\n",
    "    print(f\"Actual Sentiment: {random_y_test.iloc[i]}\")\n",
    "    print(f\"Predicted Sentiment: {random_y_pred[i]}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single review test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_arr = [input('Enter review')]\n",
    "input_vect = np.array([vectorize_text(x) for x in input_arr])\n",
    "input_pred = dt_model.predict(input_vect)\n",
    "\n",
    "for i in range(len(input_pred)):\n",
    "    print(f\"Review: {input_arr[i]}\")\n",
    "    print(f\"Sentiment: {input_pred[i]}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1ae7672e6aebabab73014c2bd743854dd04fe7451e4e03180509a948c52199c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
